mydata[mydata$word1_CODED_PRAGMATIC == 'AGENT',]$mentionSubject <- TRUE
mydata[mydata$word2_CODED_PRAGMATIC == 'AGENT',]$mentionSubject <- TRUE
mydata$mentionVerb <- FALSE
mydata[mydata$word1_CODED_PRAGMATIC == 'VERB',]$mentionVerb <- TRUE
mydata[mydata$word2_CODED_PRAGMATIC == 'VERB',]$mentionVerb <- TRUE
mydata$mentionObject <- FALSE
mydata[mydata$word1_CODED_PRAGMATIC == 'OBJECT',]$mentionObject <- TRUE
mydata[mydata$word2_CODED_PRAGMATIC == 'OBJECT',]$mentionObject <- TRUE
mydata$mentionOther <- FALSE
mydata[mydata$word1_CODED_PRAGMATIC != 'AGENT' & mydata$word1_CODED_PRAGMATIC != 'OBJECT' & mydata$word1_CODED_PRAGMATIC != 'VERB',]$mentionOther <- TRUE
mydata[mydata$word2_CODED_PRAGMATIC != 'AGENT' & mydata$word2_CODED_PRAGMATIC != 'OBJECT' & mydata$word2_CODED_PRAGMATIC != 'VERB',]$mentionOther <- TRUE
#Code whether the exact SV or VO solution was reached
mydata$mentionSV <- FALSE
mydata[mydata$mentionSubject == TRUE & mydata$mentionVerb == TRUE,]$mentionSV <- TRUE
mydata$mentionVO <- FALSE
mydata[mydata$mentionObject == TRUE & mydata$mentionVerb == TRUE,]$mentionVO <- TRUE
mydata$mentionSO <- FALSE
mydata[mydata$mentionObject == TRUE & mydata$mentionSubject == TRUE,]$mentionSO <- TRUE
################################################
#######
#DESCRIPTIVE STATISTICS
#######
################################################
#How often did people include some non AVP word?
mean(mydata$mentionOther)
#...or include NO AVP words?
nrow(mydata[(mentionSubject == FALSE & mentionObject == FALSE & mentionVerb == FALSE),])/nrow(mydata)
#Look at overall results
with(mydata, tapply(mentionSubject, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
with(mydata, tapply(mentionObject, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
with(mydata, tapply(mentionVerb, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
#Get some bootstrapped confidence intervals for these numbers
#TERRIBLE CODE ALERT there is a better way to do this.
mentionSb_1.boot.mean = bootstrap(mydata[mydata$trialVersion=="1_6",]$mentionSubject, 1000, mean)
quantile(mentionSb_1.boot.mean$thetastar, c(0.025, 0.975))
mentionSb_2.boot.mean = bootstrap(mydata[mydata$trialVersion=="2_5",]$mentionSubject, 1000, mean)
quantile(mentionSb_2.boot.mean$thetastar, c(0.025, 0.975))
mentionSb_3.boot.mean = bootstrap(mydata[mydata$trialVersion=="3_4",]$mentionSubject, 1000, mean)
quantile(mentionSb_3.boot.mean$thetastar, c(0.025, 0.975))
mentionSb_4.boot.mean = bootstrap(mydata[mydata$trialVersion=="4_3",]$mentionSubject, 1000, mean)
quantile(mentionSb_4.boot.mean$thetastar, c(0.025, 0.975))
mentionSb_5.boot.mean = bootstrap(mydata[mydata$trialVersion=="5_2",]$mentionSubject, 1000, mean)
quantile(mentionSb_5.boot.mean$thetastar, c(0.025, 0.975))
mentionSb_6.boot.mean = bootstrap(mydata[mydata$trialVersion=="6_1",]$mentionSubject, 1000, mean)
quantile(mentionSb_6.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_1.boot.mean = bootstrap(mydata[mydata$trialVersion=="1_6",]$mentionObject, 1000, mean)
quantile(mentionOb_1.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_2.boot.mean = bootstrap(mydata[mydata$trialVersion=="2_5",]$mentionObject, 1000, mean)
quantile(mentionOb_2.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_3.boot.mean = bootstrap(mydata[mydata$trialVersion=="3_4",]$mentionObject, 1000, mean)
quantile(mentionOb_3.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_4.boot.mean = bootstrap(mydata[mydata$trialVersion=="4_3",]$mentionObject, 1000, mean)
quantile(mentionOb_4.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_5.boot.mean = bootstrap(mydata[mydata$trialVersion=="5_2",]$mentionObject, 1000, mean)
quantile(mentionOb_5.boot.mean$thetastar, c(0.025, 0.975))
mentionOb_6.boot.mean = bootstrap(mydata[mydata$trialVersion=="6_1",]$mentionObject, 1000, mean)
quantile(mentionOb_6.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_1.boot.mean = bootstrap(mydata[mydata$trialVersion=="1_6",]$mentionVerb, 1000, mean)
quantile(mentionVb_1.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_2.boot.mean = bootstrap(mydata[mydata$trialVersion=="2_5",]$mentionVerb, 1000, mean)
quantile(mentionVb_2.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_3.boot.mean = bootstrap(mydata[mydata$trialVersion=="3_4",]$mentionVerb, 1000, mean)
quantile(mentionVb_3.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_4.boot.mean = bootstrap(mydata[mydata$trialVersion=="4_3",]$mentionVerb, 1000, mean)
quantile(mentionVb_4.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_5.boot.mean = bootstrap(mydata[mydata$trialVersion=="5_2",]$mentionVerb, 1000, mean)
quantile(mentionVb_5.boot.mean$thetastar, c(0.025, 0.975))
mentionVb_6.boot.mean = bootstrap(mydata[mydata$trialVersion=="6_1",]$mentionVerb, 1000, mean)
quantile(mentionVb_6.boot.mean$thetastar, c(0.025, 0.975))
########
#Lump by subject to get frequency scores (for ppl who like to see them thatway) There are 2 trials per version (1_6, etc)
mentionSubject <- aggregate(mydata$mentionSubject, by = list(mydata$Paycode, mydata$trialVersion), sum)
names(mentionSubject) <- c("Paycode", "trialVersion", "mentionSubject")
mentionObject <- aggregate(mydata$mentionObject, by = list(mydata$Paycode, mydata$trialVersion), sum)
names(mentionObject) <- c("Paycode", "trialVersion", "mentionObject")
mentionVerb <- aggregate(mydata$mentionVerb, by = list(mydata$Paycode, mydata$trialVersion), sum)
names(mentionVerb) <- c("Paycode", "trialVersion", "mentionVerb")
mentionSV <- aggregate(mydata$mentionSV, by = list(mydata$Paycode, mydata$trialVersion), sum)
names(mentionSV) <- c("Paycode", "trialVersion", "mentionSV")
mentionVO <- aggregate(mydata$mentionVO, by = list(mydata$Paycode, mydata$trialVersion), sum)
names(mentionVO) <- c("Paycode", "trialVersion", "mentionVO")
with(mentionSubject, tapply(mentionSubject, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
with(mentionObject, tapply(mentionObject, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
with(mentionVerb, tapply(mentionVerb, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
#(Check with exact SV VO solutions too)
with(mentionSV, tapply(mentionSV, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
with(mentionVO, tapply(mentionVO, list(trialVersion), mean, na.rm=TRUE), drop=TRUE)
########
# Right here, calculate empirical percentages in a random split-half, for the modeling comparisons
set.seed(223344) #to reproduce the exact values reported in the paper
cleandata <- filter(mydata, mentionOther == 0)
cleandata$randomHalf <- runif(nrow(cleandata),0,1) > 0.5
r1 <- filter(cleandata, randomHalf)
r2 <- filter(cleandata, !(randomHalf))
splithalf <- cbind(aggregate(r1$mentionSV, by = list(r1$trialVersion), mean), half = 'r1', element = 'SV')
splithalf <- rbind(splithalf, cbind(aggregate(r1$mentionVO, by = list(r1$trialVersion), mean), half = 'r1', element = 'VO'))
splithalf <- rbind(splithalf, cbind(aggregate(r1$mentionSO, by = list(r1$trialVersion), mean),half = 'r1', element = 'SO'))
splithalf <- rbind(splithalf, cbind(aggregate(r2$mentionSV, by = list(r2$trialVersion), mean), half = 'r2', element = 'SV'))
splithalf <- rbind(splithalf, cbind(aggregate(r2$mentionVO, by = list(r2$trialVersion), mean),half = 'r2', element = 'VO'))
splithalf <- rbind(splithalf, cbind(aggregate(r2$mentionSO, by = list(r2$trialVersion), mean),half = 'r2', element = 'SO'))
names(splithalf) <- c('condition', 'p_include', 'half','element')
write.csv(splithalf, 'humandata.csv')
################################################
#INFERENTIAL STATISTICS
################################################
#Recode variable (numeric/interval) for the inputs - number of subjects
mydata$nSubj <- as.numeric(mydata$trialVersion) #This works because trialVersion is coded as 6_1 (6 sub 1 ob), 5_2 (5sub 2 ob) etc.
#Make sure that item and subject codings are factors...
mydata$paycode <- as.factor(mydata$paycode)
mydata$verb <- as.factor(mydata$verb)
#To get the second set of analyses reported for human data: taking out the extreme levels of nSubj to see if everything below holds on non-deterministic cases!!!!
#mydata <- mydata[mydata$nSubj < 6 & mydata$nSubj > 1,]
#######
#We test two (nonindependent) different outcome measures, i.e. whether Subject was mentioned
#The nsubj manipulation is within-subject AND within-item, so the full random slopes model is:
full_maximal_model_subj <- glmer(mentionSubject ~ nSubj + (nSubj|paycode) +(nSubj|verb), data=mydata, family="binomial")
#(slow to converge but should get there)
#Comparison model with just random slopes:
random_slope_model_subj <- glmer(mentionSubject ~1 + (nSubj|paycode) +(nSubj|verb), data=mydata, family="binomial")
#Likelihood ratio test:
anova(full_maximal_model_subj, random_slope_model_subj)
#Changing how we report this in response to reviewer request, giving beta and se(beta)
#Note, no change to the model, just how stats reported in the paper
summary(full_maximal_model_subj)
#From a reviewer suggestion: In our main analysis, we coded nSubj as numeric/interval.
#Ordinal coding might be more correct, and stats can be examined by uncommenting the line below
#mydata$nSubj <- ordered(mydata$nSubj)
#In brief, this yields equivalent results for both mentionObject and mentionSubject tests with all
#levels, as well as equivalent results for mentionSubject with just intermediate levels (see line 318),
#but the model for mentionObject with just intermediate levels fails to converge even with
#just a single random intercept. In the interval-coding version, this model is only weakly
#significantly better than the control model, should moderate our confidence in that conclusion carefully.
#Subjects with ordinal factors: it didn't converge.  Dropped verb random slopes first, then subject random slopes
#notfull_maximal_model <- glmer(mentionSubject ~1 nSubj + (1|paycode) +(1|verb), data=mydata, family="binomial")
#notfullrandom_slope_model <- glmer(mentionSubject ~1 + (1|paycode) +(1|verb), data=mydata, family="binomial")
#Likelihood ratio test (ordinal factors)
#anova(notfull_maximal_model, notfullrandom_slope_model)
#######
#...Or ask whether object was mentioned
#Use with numeric coding
full_maximal_model_obj <- glmer(mentionObject ~ nSubj + (nSubj|paycode) +(nSubj|verb), data=mydata, family="binomial")
random_slope_model_obj <- glmer(mentionObject ~1 + (nSubj|paycode) +(nSubj|verb), data=mydata, family="binomial")
#Likelihood ratio
anova(full_maximal_model_obj, random_slope_model_obj)
#Summary
summary(full_maximal_model_obj)
#Use with ordinal coding, full dataset (doesn't converge with slopes) Note, this fails on middle-level data, which fails to converge in all cases
#notfull_maximal_model <- glmer(mentionObject ~ nSubj + (1|paycode) +(1|verb), data=mydata, family="binomial")
#notfullrandom_slope_model <- glmer(mentionObject ~1 + (1|paycode) +(1|verb), data=mydata, family="binomial")
#anova(notfull_maximal_model, notfullrandom_slope_model)
##################################
#Also look at Subject drop main effect! (People drop subjects more often than objects)
#Overall, did people tend to mention subjects, or objects?
mean(mydata$mentionSubject)
mean(mydata$mentionObject)
#Test the distribution of answers that mentioned JUST ONE of those two
mydata$Only <- "Neither"
mydata[(mydata$mentionSubject == TRUE & mydata$mentionObject == FALSE),]$Only <- "SubOnly"
mydata[(mydata$mentionSubject == FALSE & mydata$mentionObject == TRUE),]$Only <- "ObOnly"
#How many had both?
mean(mydata$Only == "Neither")
diffdata <- mydata[mydata$Only != "Neither",]
diffdata$wasOb <- diffdata$Only == "ObOnly"
#Test!
binom.test(sum(diffdata$wasOb), nrow(diffdata))
########################################
###############
# GRAPHS
###############
########################################
#Reorganize the data
mylong <- mydata %>%
gather("whichElement","isMentioned", mentionObject, mentionSubject, mentionVerb) %>%
group_by(trialVersion, whichElement) %>%
summarise(mentionMean = mean(isMentioned))
errorbarsV <- list(mentionVb_1.boot.mean,mentionVb_2.boot.mean,mentionVb_3.boot.mean,mentionVb_4.boot.mean,mentionVb_5.boot.mean,mentionVb_6.boot.mean)
errorbarsS <- list(mentionSb_1.boot.mean,mentionSb_2.boot.mean,mentionSb_3.boot.mean,mentionSb_4.boot.mean,mentionSb_5.boot.mean,mentionSb_6.boot.mean)
errorbarsO <- list(mentionOb_1.boot.mean,mentionOb_2.boot.mean,mentionOb_3.boot.mean,mentionOb_4.boot.mean,mentionOb_5.boot.mean,mentionOb_6.boot.mean)
trials <- list("1_6","2_5","3_4","4_3","5_2","6_1")
trial_label <- list("1 agent, 6 patients", "2 agents, 5 patients","3 agents, 4 patients","4 agents, 3 patients","5 agents, 2 patients","6 agents, 1 patient")
mylong$error_high <- 0
mylong$error_low <- 0
mylong$condLabel <- ""
mylong$trialLabel <- ""
mylong[mylong$whichElement == "mentionSubject",]$condLabel <- "Subject"
mylong[mylong$whichElement == "mentionObject",]$condLabel <- "Object"
mylong[mylong$whichElement == "mentionVerb",]$condLabel <- "Verb"
mylong$condLabel <- factor(mylong$condLabel, levels = c("Subject", "Object","Verb"))
for (i in 1:6) {
vv <- errorbarsV[[i]]
ss <- errorbarsS[[i]]
oo <- errorbarsO[[i]]
mylong[(mylong$trialVersion == trials[[i]]),]$trialLabel <- trial_label[[i]]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionSubject"),]$error_high <- quantile(ss$thetastar, c(0.025, 0.975))[2]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionSubject"),]$error_low <- quantile(ss$thetastar, c(0.025, 0.975))[1]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionObject"),]$error_high <- quantile(oo$thetastar, c(0.025, 0.975))[2]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionObject"),]$error_low <- quantile(oo$thetastar, c(0.025, 0.975))[1]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionVerb"),]$error_high <- quantile(vv$thetastar, c(0.025, 0.975))[2]
mylong[(mylong$trialVersion == trials[[i]]) & (mylong$whichElement == "mentionVerb"),]$error_low <- quantile(vv$thetastar, c(0.025, 0.975))[1]
}
library(RColorBrewer)
my.cols <- brewer.pal(9, "Purples")
my.cols <- rev(my.cols[4:9])
ggplot(data=mylong, aes(x=condLabel, y=mentionMean, fill=trialLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=error_high, ymax=error_low), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.5))+
xlab('') +
ylab('proportion of trials mentioning word') +
scale_fill_manual(name="", values=my.cols) +
theme_bw() +
theme(strip.background = element_blank()) +
theme(legend.key = element_blank()) +
theme(text = element_text(family="Times", size=rel(4))) +
theme(legend.text = element_text(family="Times", size=rel(4))) +
theme(axis.text = element_text(family="Times", size=rel(0.9)))
ggsave(filename="humanPerformance.jpg", width=10, height=6, units="in")
c <rm (list = ls(all = TRUE)) # Clean everything
options(warn=-1) # Boot.ci() keeps whining about needing variances for t-intervals. But we don't use those.
# Load packages
library(plyr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(Hmisc)
library(stringr)
library(RColorBrewer)
# Set your working directory!!!
######
# Load data
######
hdata <- read.csv("humandata.csv")
model.files <- list.files(pattern = '*[A-B].csv')
mdata <- data.frame(NULL)
for(f in model.files) {
tmp <- read.csv(f, header=F)
filena <- strsplit(f,c('.'), fixed=TRUE)[[1]][1]
tmp$Source <- substr(filena, 0, nchar(filena)-1)
tmp$half <- substr(filena, nchar(filena), nchar(filena))
tmp$condition <- c('1_6','2_5','3_4','4_3','5_2', '6_1')
mdata <- rbind(mdata, tmp)
}
#Those are the probabilities that a particular 2 word solution is used by a human or model
#(Note that for model comparisons we just use the trials where people produced exactly 2 of [S,V,O])
#melt mdata & hdata to match
hdata <- hdata %>%
select(-X) %>%
mutate(Source = "human")
hdata$half <- as.character(hdata$half)
hdata$halftoCompare <- ""
hdata[hdata$half == 'r1',]$halftoCompare <- "B" #humans and models reverse paired!
hdata[hdata$half == 'r2',]$halftoCompare <- "A"
mdata$halftoCompare <- mdata$half
names(mdata) <- c("SV","VO","SO", "Source","half","condition", "halftoCompare")
mdata <- mdata %>%
gather("element","p_include", 1:3)
alldata <- rbind(hdata,mdata)
#alternate form for comparing 'include word' probs
worddata <- alldata %>%
select(-half) %>%
spread(element, p_include) %>%
mutate(Agent = (SO + SV)/(SV + VO + SO)) %>%
mutate(Patient = (VO + SO)/(SV + VO + SO)) %>%
mutate(Verb = (VO + SV)/(SV + VO + SO)) %>%
select(-one_of('SO','SV','VO')) %>%
gather('Word', 'p_include', c(4:6)) %>%
spread(Source, p_include)
#For comparing utts
alldata <- alldata %>%
select(-half) %>%
spread(Source, p_include)
#########
# Get the model correlations!
#########
#(all the data, for all comparisons, easiest for reporting in paper
#(this is ok because same amt data/eachmodel))
#Note, this is by SV, VO, SO responses, again using only the humandata from 'good' answers
rcorr(alldata$human, alldata$dummycost)
rcorr(alldata$human, alldata$succeedorfail_nobase)
rcorr(alldata$human, alldata$succeedorfail)
rcorr(alldata$human, alldata$informative_nobaserate)
rcorr(alldata$human, alldata$informative_baserate)
#We could try it with transformed 'p(include word)' probs too
rcorr(worddata$human, worddata$dummycost)
rcorr(worddata$human, worddata$succeedorfail_nobase)
rcorr(worddata$human, worddata$succeedorfail)
rcorr(worddata$human, worddata$informative_nobaserate)
rcorr(worddata$human, worddata$informative_baserate)
########
# GRAPHS
########
#Average all the predictions between halves, then renormalize to
#'likelihood utterance includes X' format we use for the full human dataaset
toGraph <- alldata %>%
group_by(condition, element) %>%
summarise_each(funs(mean)) %>%
gather("model", "prediction", 4:9) %>%
spread("element", "prediction") %>%
select(-halftoCompare) %>%
mutate(Agent = (SO + SV)/(SV + VO + SO)) %>%
mutate(Patient = (VO + SO)/(SV + VO + SO)) %>%
mutate(Verb = (VO + SV)/(SV + VO + SO)) #%>%
#filter(model != 'human') #leave humans off this graph
### To make the graphs pretty
toGraph[toGraph$Agent == 0,]$Agent <- 0.01 #Make the bars show up!
toGraph[toGraph$Patient == 0,]$Patient <- 0.01
my.cols <- brewer.pal(9, "Purples")
my.cols <- rev(my.cols[4:9])
#pretty labels
trials <- list("1_6","2_5","3_4","4_3","5_2","6_1")
trial_label <- list("1 agent, 6 patients", "2 agents, 5 patients","3 agents, 4 patients","4 agents, 3 patients","5 agents, 2 patients","6 agents, 1 patient")
toGraph$trialLabel <- ""
for (i in 1:6){
toGraph[(toGraph$condition == trials[[i]]),]$trialLabel <- trial_label[[i]]
}
toGraph <- toGraph %>%
gather('Word','prob', 6:8)
toGraph$modelLabel = ""
toGraph[toGraph$model == "dummycost",]$modelLabel <- "Cost only"
toGraph[toGraph$model == "succeedorfail_nobase",]$modelLabel <- "Succeed/Fail"
toGraph[toGraph$model == "succeedorfail",]$modelLabel <- "Succeed/Fail & Cost"
toGraph[toGraph$model == "informative_nobaserate",]$modelLabel <- "Rational Speaker"
toGraph[toGraph$model == "informative_baserate",]$modelLabel <- "Rational Speaker & Cost"
toGraph[toGraph$model == "human",]$modelLabel <- "Human Performance"
toGraph$modelLabel <- as.factor(toGraph$modelLabel)
toGraph$modelLabel <- factor(toGraph$modelLabel,levels = c("Cost only","Succeed/Fail", "Succeed/Fail & Cost", "Rational Speaker", "Rational Speaker & Cost", "Human Performance"))
ggplot(data=toGraph, aes(x=Word, y=prob, fill=trialLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.5))+
xlab('') +
ylab('p(include word)') +
theme(strip.background = element_blank()) +
theme_bw() +
#theme(legend.key = element_blank()) +
theme(legend.position = 'none') +
scale_fill_manual(name="", values=my.cols) +
theme(text = element_text(family="Times", size=rel(4))) +
#theme(legend.text = element_text(family="Times", size=rel(4))) +
theme(axis.text = element_text(family="Times", size=rel(0.9))) +
facet_wrap( ~ modelLabel, ncol=3) +
theme(strip.text = element_text(family="Times", size=rel(0.9)))
setwd("~/Dropbox/_Projects/SubDrop/SubDrop-Multidistractor-Models/Models")
c <rm (list = ls(all = TRUE)) # Clean everything
options(warn=-1) # Boot.ci() keeps whining about needing variances for t-intervals. But we don't use those.
# Load packages
library(plyr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(Hmisc)
library(stringr)
library(RColorBrewer)
# Set your working directory!!!
######
# Load data
######
hdata <- read.csv("humandata.csv")
model.files <- list.files(pattern = '*[A-B].csv')
mdata <- data.frame(NULL)
for(f in model.files) {
tmp <- read.csv(f, header=F)
filena <- strsplit(f,c('.'), fixed=TRUE)[[1]][1]
tmp$Source <- substr(filena, 0, nchar(filena)-1)
tmp$half <- substr(filena, nchar(filena), nchar(filena))
tmp$condition <- c('1_6','2_5','3_4','4_3','5_2', '6_1')
mdata <- rbind(mdata, tmp)
}
#Those are the probabilities that a particular 2 word solution is used by a human or model
#(Note that for model comparisons we just use the trials where people produced exactly 2 of [S,V,O])
#melt mdata & hdata to match
hdata <- hdata %>%
select(-X) %>%
mutate(Source = "human")
hdata$half <- as.character(hdata$half)
hdata$halftoCompare <- ""
hdata[hdata$half == 'r1',]$halftoCompare <- "B" #humans and models reverse paired!
hdata[hdata$half == 'r2',]$halftoCompare <- "A"
mdata$halftoCompare <- mdata$half
names(mdata) <- c("SV","VO","SO", "Source","half","condition", "halftoCompare")
mdata <- mdata %>%
gather("element","p_include", 1:3)
alldata <- rbind(hdata,mdata)
#alternate form for comparing 'include word' probs
worddata <- alldata %>%
select(-half) %>%
spread(element, p_include) %>%
mutate(Agent = (SO + SV)/(SV + VO + SO)) %>%
mutate(Patient = (VO + SO)/(SV + VO + SO)) %>%
mutate(Verb = (VO + SV)/(SV + VO + SO)) %>%
select(-one_of('SO','SV','VO')) %>%
gather('Word', 'p_include', c(4:6)) %>%
spread(Source, p_include)
#For comparing utts
alldata <- alldata %>%
select(-half) %>%
spread(Source, p_include)
#########
# Get the model correlations!
#########
#(all the data, for all comparisons, easiest for reporting in paper
#(this is ok because same amt data/eachmodel))
#Note, this is by SV, VO, SO responses, again using only the humandata from 'good' answers
rcorr(alldata$human, alldata$dummycost)
rcorr(alldata$human, alldata$succeedorfail_nobase)
rcorr(alldata$human, alldata$succeedorfail)
rcorr(alldata$human, alldata$informative_nobaserate)
rcorr(alldata$human, alldata$informative_baserate)
#We could try it with transformed 'p(include word)' probs too
rcorr(worddata$human, worddata$dummycost)
rcorr(worddata$human, worddata$succeedorfail_nobase)
rcorr(worddata$human, worddata$succeedorfail)
rcorr(worddata$human, worddata$informative_nobaserate)
rcorr(worddata$human, worddata$informative_baserate)
#Average all the predictions between halves, then renormalize to
#'likelihood utterance includes X' format we use for the full human dataaset
toGraph <- alldata %>%
group_by(condition, element) %>%
summarise_each(funs(mean)) %>%
gather("model", "prediction", 4:9) %>%
spread("element", "prediction") %>%
select(-halftoCompare) %>%
mutate(Agent = (SO + SV)/(SV + VO + SO)) %>%
mutate(Patient = (VO + SO)/(SV + VO + SO)) %>%
mutate(Verb = (VO + SV)/(SV + VO + SO)) #%>%
#filter(model != 'human') #leave humans off this graph
### To make the graphs pretty
toGraph[toGraph$Agent == 0,]$Agent <- 0.01 #Make the bars show up!
toGraph[toGraph$Patient == 0,]$Patient <- 0.01
my.cols <- brewer.pal(9, "Purples")
my.cols <- rev(my.cols[4:9])
#pretty labels
trials <- list("1_6","2_5","3_4","4_3","5_2","6_1")
trial_label <- list("1 agent, 6 patients", "2 agents, 5 patients","3 agents, 4 patients","4 agents, 3 patients","5 agents, 2 patients","6 agents, 1 patient")
toGraph$trialLabel <- ""
for (i in 1:6){
toGraph[(toGraph$condition == trials[[i]]),]$trialLabel <- trial_label[[i]]
}
toGraph <- toGraph %>%
gather('Word','prob', 6:8)
toGraph$modelLabel = ""
toGraph[toGraph$model == "dummycost",]$modelLabel <- "Cost only"
toGraph[toGraph$model == "succeedorfail_nobase",]$modelLabel <- "Succeed/Fail"
toGraph[toGraph$model == "succeedorfail",]$modelLabel <- "Succeed/Fail & Cost"
toGraph[toGraph$model == "informative_nobaserate",]$modelLabel <- "Rational Speaker"
toGraph[toGraph$model == "informative_baserate",]$modelLabel <- "Rational Speaker & Cost"
toGraph[toGraph$model == "human",]$modelLabel <- "Human Performance"
toGraph$modelLabel <- as.factor(toGraph$modelLabel)
toGraph$modelLabel <- factor(toGraph$modelLabel,levels = c("Cost only","Succeed/Fail", "Succeed/Fail & Cost", "Rational Speaker", "Rational Speaker & Cost", "Human Performance"))
ggplot(data=toGraph, aes(x=Word, y=prob, fill=trialLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.5))+
xlab('') +
ylab('p(include word)') +
theme(strip.background = element_blank()) +
theme_bw() +
#theme(legend.key = element_blank()) +
theme(legend.position = 'none') +
scale_fill_manual(name="", values=my.cols) +
theme(text = element_text(family="Times", size=rel(4))) +
#theme(legend.text = element_text(family="Times", size=rel(4))) +
theme(axis.text = element_text(family="Times", size=rel(0.9))) +
facet_wrap( ~ modelLabel, ncol=3) +
theme(strip.text = element_text(family="Times", size=rel(0.9)))
names(toGraph)
toGraph$model
toGraph <- filter(toGraph, c("succeedorfail", "human", "dummycost", "informative_nobaserate"))
library(dplyr)
toGraph <- filter(toGraph %in% c("succeedorfail", "human", "dummycost", "informative_nobaserate"))
toGraph <- filter(toGraph, model %in% c("succeedorfail", "human", "dummycost", "informative_nobaserate"))
View(toGraph)
ggplot(data=toGraph, aes(x=Word, y=prob, fill=trialLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.5))+
xlab('') +
ylab('p(include word)') +
theme(strip.background = element_blank()) +
theme_bw() +
#theme(legend.key = element_blank()) +
theme(legend.position = 'none') +
scale_fill_manual(name="", values=my.cols) +
theme(text = element_text(family="Times", size=rel(4))) +
#theme(legend.text = element_text(family="Times", size=rel(4))) +
theme(axis.text = element_text(family="Times", size=rel(0.9))) +
facet_wrap( ~ modelLabel, ncol=3) +
theme(strip.text = element_text(family="Times", size=rel(0.9)))
toGraph <- filter(toGraph, model %in% c("succeedorfail", "human", "dummycost", "informative_nobaserate"))
ggplot(data=toGraph, aes(x=Word, y=prob, fill=trialLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.5))+
xlab('') +
ylab('p(include word)') +
theme(strip.background = element_blank()) +
theme_bw() +
#theme(legend.key = element_blank()) +
theme(legend.position = 'none') +
scale_fill_manual(name="", values=my.cols) +
theme(text = element_text(family="Times", size=rel(4))) +
#theme(legend.text = element_text(family="Times", size=rel(4))) +
theme(axis.text = element_text(family="Times", size=rel(0.9))) +
facet_wrap( ~ modelLabel, ncol=2) +
theme(strip.text = element_text(family="Times", size=rel(0.9)))
11*.9
8*.9
11 * .8
8 * .9
8 * .8
ggsave(filename="fourmodels_nolegend_forpaper.jpg", width=7, height=6.5)
